---
---

@article{snugglesense,
  title={SnuggleSense: Empowering Online Harm Survivors Through a Structured Sensemaking Process},
  author={Xiao, Sijia and Zou, Haodi and Mathews, Amy and Rui, Jingshu and Cheshire, Coye and Salehi, Niloufar},
  year={2025},
  journal={CSCW},
  preview={snugglesense.png},
  selected={true}
}

@article{sage,
  title={SAGE: System for Accessible Guided Exploration of Health Information},
  author={Alam, Sabriya M. and Zou, Haodi and Vir, Reya and Salehi, Niloufar},
  abstract={The Center for Disease Control estimates that six in ten adults in the United States currently live with a chronic disease such as cancer, heart disease, or diabetes. Yet most patients lack sufficient access to comprehensible information and guidance for effective self-management of chronic conditions and remain unaware of gaps in their knowledge. To address this challenge, we introduce SAGE, a System for Accessible Guided Exploration of healthcare information. SAGE is an information system that leverages Large Language Models (LLMs) to help patients identify and fill gaps in their understanding through automated organization of healthcare information, generation of guiding questions, and retrieval of reliable and accurate answers to patient queries. While LLMs may be a powerful intervention for these tasks, they pose risks and lack reliability in such high-stakes settings. One approach to address these limitations is to augment LLMs with Knowledge Graphs (KGs) containing well-structured and pre-verified health information. Thus, SAGE demonstrates how LLMs and KGs can complement each other to aid in the construction and retrieval of structured knowledge. By integrating the flexibility and natural language capabilities of LLMs with the reliability of KGs, SAGE seeks to create a collaborative system that promotes knowledge discovery for informed decision-making and effective self-management of chronic conditions.},
  year={2024},
  journal={AAAI Workshop on Public Sector LLMs: Algorithmic and Sociotechnical Design},
  preview={sage.png},
  html={https://openreview.net/forum?id=hoP4Ko8nf6},
  pdf={https://openreview.net/pdf?id=hoP4Ko8nf6},
  selected={true}
}

@article{aloha,
  title={ALOHa: A New Measure for Hallucination in Captioning Models},
  author={Petryk*, Suzanne and Chan*, David and Kachinthaya, Anish and Zou, Haodi and Canny, John and Gonzalez, Joseph E. and Darrell, Trevor},
  abstract={Despite recent advances in multimodal pre-training for visual description, state-of-the-art models still produce captions containing errors, such as hallucinating objects not present in a scene. The existing prominent metric for object hallucination, CHAIR, is limited to a fixed set of MS COCO objects and synonyms. In this work, we propose a modernized open-vocabulary metric, ALOHa, which leverages large language models (LLMs) to measure object hallucinations. Specifically, we use an LLM to extract groundable objects from a candidate caption, measure their semantic similarity to reference objects from captions and object detections, and use Hungarian matching to produce a final hallucination score. We show that ALOHa correctly identifies 13.6% more hallucinated objects than CHAIR on HAT, a new gold-standard subset of MS COCO Captions annotated for hallucinations, and 30.8% more on nocaps, where objects extend beyond MS COCO categories.},
  year={2024},
  journal={Annual Conference of the North American Chapter of the Association for Computational Linguistics (NACCL)},
  html={https://arxiv.org/abs/2404.02904},
  pdf={https://arxiv.org/pdf/2404.02904},
  selected={false}
}
